import streamlit as st
import cv2
import numpy as np
from PIL import Image
from keras.models import load_model
from gtts import gTTS
import platform
import time
import io

# ===============================
# CONFIGURACI√ìN DE LA P√ÅGINA
# ===============================
st.set_page_config(
    page_title="Centro de Control Gestual ‚Äì Misi√≥n A.R.G.O.S.",
    page_icon="üöÄ",
    layout="centered"
)

# ===============================
# CARGA DEL MODELO
# ===============================
model = load_model('keras_model.h5')
data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)

# ===============================
# INTERFAZ PRINCIPAL
# ===============================
st.title("üöÄ Centro de Control Gestual A.R.G.O.S.")
st.caption("Sistema de reconocimiento de gestos para navegaci√≥n espacial")

# Imagen decorativa (futurista o de la nave)
st.image("OIG5.jpg", width=320, caption="Unidad de an√°lisis visual A.R.G.O.S. en l√≠nea")

st.markdown("---")
st.text(f"Versi√≥n del sistema: Python {platform.python_version()} | N√∫cleo Visual A.R.G.O.S. v1.5")

# ===============================
# SIDEBAR
# ===============================
with st.sidebar:
    st.subheader("üì° M√≥dulo de entrenamiento activo")
    st.info("Este sistema usa un modelo de **Teachable Machine** para interpretar gestos como comandos espaciales.")
    st.write("Captura un gesto frente a la c√°mara para ejecutar una orden.")

# ===============================
# CAPTURA DE IMAGEN
# ===============================
st.markdown("### üé• Esc√°ner de Comando Gestual")
img_file_buffer = st.camera_input("Activa la c√°mara y realiza tu gesto")

# ===============================
# PROCESAMIENTO DE LA IMAGEN
# ===============================
if img_file_buffer is not None:
    # Cargar imagen
    img = Image.open(img_file_buffer)
    img_resized = img.resize((224, 224))
    img_array = np.array(img_resized)

    # Normalizar
    normalized_image_array = (img_array.astype(np.float32) / 127.0) - 1
    data[0] = normalized_image_array

    # Ejecutar predicci√≥n
    with st.spinner("üîç Analizando gesto..."):
        time.sleep(1)
        prediction = model.predict(data)
    
    st.success("‚úÖ Comando recibido con √©xito")

    # ===============================
    # INTERPRETACI√ìN Y RESULTADOS
    # ===============================
    mensaje = ""
    if prediction[0][0] > 0.5:
        st.subheader("üñêÔ∏è Gesto detectado: **IZQUIERDA**")
        st.write(f"Probabilidad: {prediction[0][0]:.2%}")
        mensaje = "Comando recibido: activando propulsores laterales izquierdos."
        st.caption(mensaje)

    elif prediction[0][1] > 0.5:
        st.subheader("‚úã Gesto detectado: **ARRIBA**")
        st.write(f"Probabilidad: {prediction[0][1]:.2%}")
        mensaje = "Comando recibido: elevando la nave a coordenadas superiores."
        st.caption(mensaje)

    else:
        st.subheader("ü§∑‚Äç‚ôÇÔ∏è Gesto no reconocido")
        mensaje = "Comando no v√°lido. Por favor, intenta nuevamente."
        st.caption(mensaje)

    # ===============================
    # GENERAR AUDIO AUTOM√ÅTICAMENTE
    # ===============================
    if mensaje:
        tts = gTTS(text=mensaje, lang='es')
        audio_bytes = io.BytesIO()
        tts.write_to_fp(audio_bytes)
        st.audio(audio_bytes.getvalue(), format="audio/mp3")

# ===============================
# PIE DE P√ÅGINA
# ===============================
st.markdown("---")
st.caption("""
üõ∞Ô∏è **Centro de Control Gestual A.R.G.O.S.**  
Proyecto experimental de reconocimiento de gestos.  
Desarrollado con **Streamlit + Keras + gTTS + Teachable Machine**.  
""")


